{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v5.json", "dbt_version": "1.7.4", "generated_at": "2024-03-15T20:12:03.757416Z", "invocation_id": "90caca3f-a2f5-49a3-8fa5-119ddbc2c14c", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.875987Z", "completed_at": "2024-03-15T20:12:02.885591Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.897590Z", "completed_at": "2024-03-15T20:12:02.897607Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.022938966751098633, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__account", "compiled": true, "compiled_code": "with base as (\n    \n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests\".\"account\"\n),\n\nfields as (\n\n    select\n        id as account_id,\n        country,\n        cast(created_at as timestamp) as created_at,\n        name as account_name,\n        status\n    from base\n)\n\nselect * \nfrom fields", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__account\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.894731Z", "completed_at": "2024-03-15T20:12:02.898644Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.900894Z", "completed_at": "2024-03-15T20:12:02.900899Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.017341136932373047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__destination", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests\".\"destination\"\n),\n\nfields as (\n\n    select\n        id as destination_id,\n        account_id,\n        cast(created_at as timestamp) as created_at,\n        name as destination_name,\n        region\n    from base\n)\n\nselect * \nfrom fields", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.888657Z", "completed_at": "2024-03-15T20:12:02.899181Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.901367Z", "completed_at": "2024-03-15T20:12:02.901370Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.021717071533203125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__credits_used", "compiled": true, "compiled_code": "\n\nwith base as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests\".\"credits_used\"\n),\n\nfields as (\n    \n    select \n        destination_id,\n        measured_month,\n        credits_consumed as credits_spent\n    from base\n)\n\nselect * \nfrom fields\n\n", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__credits_used\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.886084Z", "completed_at": "2024-03-15T20:12:02.899428Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.901614Z", "completed_at": "2024-03-15T20:12:02.901616Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.022840023040771484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__connector_tmp", "compiled": true, "compiled_code": "select *\nfrom \"postgres\".\"fivetran_platform_integration_tests\".\"connector\"", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__connector_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.902378Z", "completed_at": "2024-03-15T20:12:02.907979Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.910448Z", "completed_at": "2024-03-15T20:12:02.910453Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02072000503540039, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__destination_membership", "compiled": true, "compiled_code": "\n\nwith base as (\n    \n    select * from \"postgres\".\"fivetran_platform_integration_tests\".\"destination_membership\"\n),\n\nfields as (\n\n    select\n        destination_id,\n        user_id,\n        cast(activated_at as timestamp) as activated_at,\n        cast(joined_at as timestamp) as joined_at,\n        role as destination_role\n    from base\n)\n\nselect * \nfrom fields", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination_membership\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.910739Z", "completed_at": "2024-03-15T20:12:02.922348Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.926964Z", "completed_at": "2024-03-15T20:12:02.926969Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01999521255493164, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__incremental_mar", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests\".\"incremental_mar\"\n),\n\nfields as (\n\n    select\n        connector_id as connector_name,\n        destination_id,\n        free_type,\n        cast(measured_date as timestamp) as measured_date,\n        schema_name,\n        sync_type,\n        table_name,\n        updated_at,\n        _fivetran_synced,\n        incremental_rows\n    from base\n)\n\nselect * \nfrom fields", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__incremental_mar\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.916112Z", "completed_at": "2024-03-15T20:12:02.922624Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.927263Z", "completed_at": "2024-03-15T20:12:02.927267Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.019704103469848633, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__usage_cost", "compiled": true, "compiled_code": "\nwith base as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests\".\"usage_cost\"\n),\n\nfields as (\n    \n    select \n        destination_id,\n        measured_month,\n        amount as dollars_spent\n    from base\n)\n\nselect * \nfrom fields\n\n", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__usage_cost\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.913706Z", "completed_at": "2024-03-15T20:12:02.922953Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.927538Z", "completed_at": "2024-03-15T20:12:02.927541Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0205230712890625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__log_tmp", "compiled": true, "compiled_code": "select *\nfrom \"postgres\".\"fivetran_platform_integration_tests\".\"log\"", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log_tmp\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.923248Z", "completed_at": "2024-03-15T20:12:02.927782Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.930628Z", "completed_at": "2024-03-15T20:12:02.930631Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.010298728942871094, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__user", "compiled": true, "compiled_code": "\n\nwith base as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests\".\"user\"\n),\n\nfields as (\n\n    select\n        id as user_id,\n        cast(created_at as timestamp) as created_at,\n        email,\n        email_disabled as has_disabled_email_notifications,\n        family_name as last_name,\n        given_name as first_name,\n        phone,\n        verified as is_verified\n    from base\n)\n\nselect * \nfrom fields", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__user\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.933382Z", "completed_at": "2024-03-15T20:12:02.934587Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.939657Z", "completed_at": "2024-03-15T20:12:02.939664Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.011110305786132812, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.account", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.934956Z", "completed_at": "2024-03-15T20:12:02.936026Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.939956Z", "completed_at": "2024-03-15T20:12:02.939960Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.011212825775146484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.connector", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.936326Z", "completed_at": "2024-03-15T20:12:02.937987Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.940235Z", "completed_at": "2024-03-15T20:12:02.940238Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.011327028274536133, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.credits_used", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.940489Z", "completed_at": "2024-03-15T20:12:02.941558Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.944215Z", "completed_at": "2024-03-15T20:12:02.944219Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.0073468685150146484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.destination", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.946996Z", "completed_at": "2024-03-15T20:12:02.948031Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.952066Z", "completed_at": "2024-03-15T20:12:02.952071Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01061701774597168, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.destination_membership", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.948342Z", "completed_at": "2024-03-15T20:12:02.949328Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.952325Z", "completed_at": "2024-03-15T20:12:02.952328Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.010706186294555664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.incremental_mar", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.949609Z", "completed_at": "2024-03-15T20:12:02.950585Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.952577Z", "completed_at": "2024-03-15T20:12:02.952582Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.010816097259521484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.log", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.952848Z", "completed_at": "2024-03-15T20:12:02.954601Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.957243Z", "completed_at": "2024-03-15T20:12:02.957247Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.007924079895019531, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.usage_cost", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.959990Z", "completed_at": "2024-03-15T20:12:02.961189Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.972991Z", "completed_at": "2024-03-15T20:12:02.972997Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.018742084503173828, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.fivetran_log_integration_tests.user", "compiled": null, "compiled_code": null, "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.968271Z", "completed_at": "2024-03-15T20:12:02.976610Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.978691Z", "completed_at": "2024-03-15T20:12:02.978697Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.022533178329467773, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.unique_stg_fivetran_platform__account_account_id.114e181adc", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    account_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__account\"\nwhere account_id is not null\ngroup by account_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.961501Z", "completed_at": "2024-03-15T20:12:02.976867Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.979908Z", "completed_at": "2024-03-15T20:12:02.979912Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.023368120193481445, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.not_null_stg_fivetran_platform__account_account_id.d09ebf1a1e", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect account_id\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__account\"\nwhere account_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.973274Z", "completed_at": "2024-03-15T20:12:02.977986Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:02.981605Z", "completed_at": "2024-03-15T20:12:02.981608Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.04249119758605957, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.not_null_stg_fivetran_platform__destination_destination_id.0cdbe6b780", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect destination_id\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination\"\nwhere destination_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:02.981863Z", "completed_at": "2024-03-15T20:12:03.016318Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.029557Z", "completed_at": "2024-03-15T20:12:03.029564Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.0555577278137207, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.unique_stg_fivetran_platform__destination_destination_id.582a1280ed", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    destination_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination\"\nwhere destination_id is not null\ngroup by destination_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.017367Z", "completed_at": "2024-03-15T20:12:03.034200Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.036109Z", "completed_at": "2024-03-15T20:12:03.036113Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.022140979766845703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_stg_fivetran_platform__credits_used_measured_month__destination_id.bea8f20c38", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        measured_month, destination_id\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__credits_used\"\n    group by measured_month, destination_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.030130Z", "completed_at": "2024-03-15T20:12:03.035429Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.037395Z", "completed_at": "2024-03-15T20:12:03.037398Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.024286985397338867, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_stg_fivetran_platform__destination_membership_destination_id__user_id.82ac27c35a", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        destination_id, user_id\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination_membership\"\n    group by destination_id, user_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.037683Z", "completed_at": "2024-03-15T20:12:03.042182Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.047456Z", "completed_at": "2024-03-15T20:12:03.047462Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.015718936920166016, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_stg_fivetran_platform__usage_cost_measured_month__destination_id.d6d997525f", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        measured_month, destination_id\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__usage_cost\"\n    group by measured_month, destination_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.047990Z", "completed_at": "2024-03-15T20:12:03.055902Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.056457Z", "completed_at": "2024-03-15T20:12:03.056462Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.014230012893676758, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.not_null_stg_fivetran_platform__user_user_id.eb17e92ff0", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect user_id\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__user\"\nwhere user_id is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.053115Z", "completed_at": "2024-03-15T20:12:03.057517Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.058016Z", "completed_at": "2024-03-15T20:12:03.058019Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.006014823913574219, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.unique_stg_fivetran_platform__user_user_id.86a1a3afb9", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    user_id as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__user\"\nwhere user_id is not null\ngroup by user_id\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.023340Z", "completed_at": "2024-03-15T20:12:03.303163Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.303719Z", "completed_at": "2024-03-15T20:12:03.303726Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.3139369487762451, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__connector", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__connector_tmp\"\n),\n\nfields as (\n    select\n        \n    \n    \n    _fivetran_deleted\n    \n as \n    \n    _fivetran_deleted\n    \n, \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    connecting_user_id\n    \n as \n    \n    connecting_user_id\n    \n, \n    \n    \n    connector_id\n    \n as \n    \n    connector_id\n    \n, \n    \n    \n    connector_name\n    \n as \n    \n    connector_name\n    \n, \n    \n    \n    connector_type\n    \n as \n    \n    connector_type\n    \n, \n    cast(null as TEXT) as \n    \n    connector_type_id\n    \n , \n    \n    \n    destination_id\n    \n as \n    \n    destination_id\n    \n, \n    \n    \n    paused\n    \n as \n    \n    paused\n    \n, \n    cast(null as integer) as \n    \n    service_version\n    \n , \n    \n    \n    signed_up\n    \n as \n    \n    signed_up\n    \n\n\n\n        ,row_number() over ( partition by connector_name, destination_id order by _fivetran_synced desc ) as nth_last_record\n    from base\n),\n\nfinal as (\n\n    select \n        connector_id,\n        connector_name,\n        coalesce(connector_type_id, connector_type) as connector_type,\n        destination_id,\n        connecting_user_id,\n        paused as is_paused,\n        signed_up as set_up_at,\n        coalesce(_fivetran_deleted, false) as is_deleted\n    from fields\n\n    -- Only look at the most recent one\n    where nth_last_record = 1\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__connector\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.043300Z", "completed_at": "2024-03-15T20:12:03.304242Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.304732Z", "completed_at": "2024-03-15T20:12:03.304736Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.28835105895996094, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.stg_fivetran_platform__log", "compiled": true, "compiled_code": "with base as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log_tmp\"\n),\n\nfields as (\n    select\n        \n    \n    \n    _fivetran_synced\n    \n as \n    \n    _fivetran_synced\n    \n, \n    \n    \n    connector_id\n    \n as \n    \n    connector_id\n    \n, \n    \n    \n    event\n    \n as \n    \n    event\n    \n, \n    \n    \n    id\n    \n as \n    \n    id\n    \n, \n    \n    \n    message_data\n    \n as \n    \n    message_data\n    \n, \n    \n    \n    message_event\n    \n as \n    \n    message_event\n    \n, \n    \n    \n    sync_id\n    \n as \n    \n    sync_id\n    \n, \n    \n    \n    time_stamp\n    \n as \n    \n    time_stamp\n    \n, \n    \n    \n    transformation_id\n    \n as \n    \n    transformation_id\n    \n\n\n\n    from base\n),\n\nfinal as (\n\n    select\n        id as log_id, \n        sync_id,\n        cast(time_stamp as timestamp) as created_at,\n        connector_id, -- Note: the connector_id column used to erroneously equal the connector_name, NOT its id.\n        case when transformation_id is not null and event is null then 'TRANSFORMATION'\n        else event end as event_type, \n        message_data,\n        case \n        when transformation_id is not null and message_data like '%has succeeded%' then 'transformation run success'\n        when transformation_id is not null and message_data like '%has failed%' then 'transformation run failed'\n        else message_event end as event_subtype,\n        transformation_id\n    from fields\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.333613Z", "completed_at": "2024-03-15T20:12:03.360426Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.361748Z", "completed_at": "2024-03-15T20:12:03.361756Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.031939029693603516, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.fivetran_platform__mar_table_history", "compiled": true, "compiled_code": "with incremental_mar as (\n\n    select\n        *,\n        date_trunc('month', measured_date) as measured_month\n\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__incremental_mar\"\n),\n\nconnector as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__connector\"\n),\n\ndestination as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination\"\n),\n\nordered_mar as (\n\n    select\n        connector_name,\n        schema_name,\n        table_name,\n        destination_id,\n        measured_month,\n        max(measured_date) as last_measured_at,\n        sum(incremental_rows) as incremental_rows,\n        sum(coalesce(case when lower(free_type) = 'paid'\n            then incremental_rows\n        end, 0)) as paid_monthly_active_rows,\n        sum(coalesce(case when lower(free_type) != 'paid'\n            then incremental_rows\n        end, 0)) as free_monthly_active_rows\n\n    from incremental_mar\n    group by connector_name, schema_name, table_name, destination_id, measured_month\n),\n\nlatest_mar as (\n    select \n        connector_name,\n        schema_name,\n        table_name,\n        destination_id,\n        measured_month,\n        cast(last_measured_at as date) as last_measured_at,\n        free_monthly_active_rows,\n        paid_monthly_active_rows,\n        (free_monthly_active_rows + paid_monthly_active_rows) as total_monthly_active_rows\n\n    from ordered_mar\n),\n\nmar_join as (\n\n    select\n        latest_mar.*,\n        connector.connector_type,\n        connector.connector_id,\n        destination.destination_name\n\n    from latest_mar\n    join connector\n        on latest_mar.connector_name = connector.connector_name\n        and latest_mar.destination_id = connector.destination_id\n    join destination on latest_mar.destination_id = destination.destination_id\n)\n\nselect * from mar_join", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__mar_table_history\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.340801Z", "completed_at": "2024-03-15T20:12:03.362118Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.364951Z", "completed_at": "2024-03-15T20:12:03.364956Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.03442883491516113, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.fivetran_platform__audit_user_activity", "compiled": true, "compiled_code": "with logs as (\n\n    select \n        *,\n        \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{a,c,t,o,r}'\n    else null end\n\n as actor_email\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\"\n    where lower(message_data) like '%actor%'\n),\n\nuser_logs as (\n\n    select *\n    from logs\n    where actor_email is not null \n        and lower(actor_email) != 'fivetran'\n),\n\nconnector as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__connector\"\n),\n\ndestination as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination\"\n),\nusers as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__user\"\n),\n    destination_membership as (\n\n        select *\n        from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination_membership\"\n    ),\n    final as (\n\n    select\n        date_trunc('day', user_logs.created_at) as date_day,\n        \n        to_char(user_logs.created_at, 'FMDy') as day_name,\n            date_part('day', user_logs.created_at) as day_of_month,\n        user_logs.created_at as occurred_at,\n        destination.destination_name,\n        destination.destination_id,\n        connector.connector_name,\n        connector.connector_id,\n        user_logs.actor_email as email,\n        users.first_name,\n        users.last_name,\n        users.user_id,\n        destination_membership.destination_role,\n    user_logs.event_type, -- should always be INFO for user-triggered actions but include just in case\n        user_logs.event_subtype,\n        user_logs.message_data,\n        user_logs.log_id\n\n    from user_logs\n    left join connector\n        on user_logs.connector_id = connector.connector_id\n    left join destination\n        on connector.destination_id = destination.destination_id\n    left join users \n        on lower(users.email) = lower(user_logs.actor_email)\n    left join destination_membership\n        on destination.destination_id = destination_membership.destination_id\n        and users.user_id = destination_membership.user_id\n\n    )\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__audit_user_activity\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.350229Z", "completed_at": "2024-03-15T20:12:03.362382Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.365305Z", "completed_at": "2024-03-15T20:12:03.365312Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.034352779388427734, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.fivetran_platform__connector_status", "compiled": true, "compiled_code": "with transformation_removal as (\n\n    select \n        *,\n        case when event_subtype in ('status', 'sync_end')\n            then message_data\n            else null \n        end as filtered_message_data\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\"\n    where transformation_id is null\n),\n\nparse_json as (\n    select\n        *,\n        \n\n  case when filtered_message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then filtered_message_data::json #>> '{status}'\n    else null end\n\n as log_status,\n        \n\n  case when filtered_message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then filtered_message_data::json #>> '{reason}'\n    else null end\n\n as log_reason\n    from transformation_removal\n),\n\nconnector_log as (\n    select \n        *,\n        sum( case when event_subtype in ('sync_start') then 1 else 0 end) over ( partition by connector_id \n            order by created_at rows unbounded preceding) as sync_batch_id\n    from parse_json\n    -- only looking at errors, warnings, and syncs here\n    where event_type = 'SEVERE'\n        or event_type = 'WARNING'\n        or event_subtype like 'sync%'\n        or (event_subtype = 'status' \n            and log_status = 'RESCHEDULED'\n            and log_reason like '%intended behavior%'\n            ) -- for priority-first syncs. these should be captured by event_type = 'WARNING' but let's make sure\n        or (event_subtype = 'status' \n            and log_status = 'SUCCESSFUL'\n        )\n        -- whole reason is \"We have rescheduled the connector to force flush data from the forward sync into your destination. This is intended behavior and means that the connector is working as expected.\"\n),\n\nschema_changes as (\n\n    select\n        connector_id,\n        count(*) as number_of_schema_changes_last_month\n\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\"\n\n    where \n        \n        ((\n    current_timestamp::timestamp\n)::date - (created_at)::date)\n     <= 30\n        and event_subtype in ('create_table', 'alter_table', 'create_schema', 'change_schema_config')\n\n    group by connector_id\n\n),\n\nconnector as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__connector\"\n\n),\n\ndestination as (\n\n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__destination\"\n),\n\nconnector_metrics as (\n\n    select\n        connector.connector_id,\n        connector.connector_name,\n        connector.connector_type,\n        connector.destination_id,\n        connector.is_paused,\n        connector.set_up_at,\n        connector.is_deleted,\n        max(case when connector_log.event_subtype = 'sync_start' then connector_log.created_at else null end) as last_sync_started_at,\n\n        max(case when connector_log.event_subtype = 'sync_end' \n            then connector_log.created_at else null end) as last_sync_completed_at,\n\n        max(case when connector_log.event_subtype in ('status', 'sync_end')\n                and connector_log.log_status = 'SUCCESSFUL'\n            then connector_log.created_at else null end) as last_successful_sync_completed_at,\n\n\n        max(case when connector_log.event_subtype = 'sync_end' \n            then connector_log.sync_batch_id else null end) as last_sync_batch_id,\n\n        max(case when connector_log.event_subtype in ('status', 'sync_end')\n                and connector_log.log_status = 'RESCHEDULED'\n                and connector_log.log_reason like '%intended behavior%'\n            then connector_log.created_at else null end) as last_priority_first_sync_completed_at,\n                \n\n        max(case when connector_log.event_type = 'SEVERE' then connector_log.created_at else null end) as last_error_at,\n\n        max(case when connector_log.event_type = 'SEVERE' then connector_log.sync_batch_id else null end) as last_error_batch,\n        max(case when event_type = 'WARNING' then connector_log.created_at else null end) as last_warning_at\n\n    from connector \n    left join connector_log \n        on connector_log.connector_id = connector.connector_id\n    group by connector.connector_id, connector.connector_name, connector.connector_type, connector.destination_id, connector.is_paused, connector.set_up_at, connector.is_deleted\n),\n\nconnector_health_status as (\n\n    select\n        *,\n        case \n            -- connector is deleted\n            when is_deleted  then 'deleted'\n\n            -- connector is paused\n            when is_paused  then 'paused'\n\n            -- a sync has never been attempted\n            when last_sync_started_at is null then 'incomplete'\n\n            -- a priority-first sync has occurred, but a normal sync has not\n            when last_priority_first_sync_completed_at is not null and last_sync_completed_at is null then 'priority first sync'\n\n            -- a priority sync has occurred more recently than a normal one (may occurr if the connector has been paused and resumed)\n            when last_priority_first_sync_completed_at > last_sync_completed_at then 'priority first sync'\n\n            -- a sync has been attempted, but not completed, and it's not due to errors. also a priority-first sync hasn't\n            when last_sync_completed_at is null and last_error_at is null then 'initial sync in progress'\n\n            -- the last attempted sync had an error\n            when last_sync_batch_id = last_error_batch then 'broken'\n\n            -- there's never been a successful sync and there have been errors\n            when last_sync_completed_at is null and last_error_at is not null then 'broken'\n\n        else 'connected' end as connector_health\n\n    from connector_metrics\n),\n\n-- Joining with log to grab pertinent error/warning messagees\nconnector_recent_logs as (\n\n    select \n        connector_health_status.connector_id,\n        connector_health_status.connector_name,\n        connector_health_status.connector_type,\n        connector_health_status.destination_id,\n        connector_health_status.connector_health,\n        connector_health_status.last_successful_sync_completed_at,\n        connector_health_status.last_sync_started_at,\n        connector_health_status.last_sync_completed_at,\n        connector_health_status.set_up_at,\n        connector_log.event_subtype,\n        connector_log.event_type,\n        connector_log.message_data\n\n    from connector_health_status \n    left join connector_log \n        on connector_log.connector_id = connector_health_status.connector_id\n        -- limiting relevance to since the last successful sync completion (if there has been one)\n        and connector_log.created_at > coalesce(connector_health_status.last_sync_completed_at, connector_health_status.last_priority_first_sync_completed_at, '2000-01-01') \n        -- only looking at errors and warnings (excluding syncs - both normal and priority first)\n        and connector_log.event_type != 'INFO' \n        -- need to explicitly avoid priority first statuses because they are of event_type WARNING\n        and not (connector_log.event_subtype = 'status' \n            and connector_log.log_status = 'RESCHEDULED'\n            and connector_log.log_reason like '%intended behavior%')\n\n    group by -- remove duplicates, need explicit group by for SQL Server\n        connector_health_status.connector_id,\n        connector_health_status.connector_name,\n        connector_health_status.connector_type,\n        connector_health_status.destination_id,\n        connector_health_status.connector_health,\n        connector_health_status.last_successful_sync_completed_at,\n        connector_health_status.last_sync_started_at,\n        connector_health_status.last_sync_completed_at,\n        connector_health_status.set_up_at,\n        connector_log.event_subtype,\n        connector_log.event_type,\n        connector_log.message_data\n),\n\nfinal as (\n\n    select\n        connector_recent_logs.connector_id,\n        connector_recent_logs.connector_name,\n        connector_recent_logs.connector_type,\n        connector_recent_logs.destination_id,\n        destination.destination_name,\n        connector_recent_logs.connector_health,\n        connector_recent_logs.last_successful_sync_completed_at,\n        connector_recent_logs.last_sync_started_at,\n        connector_recent_logs.last_sync_completed_at,\n        connector_recent_logs.set_up_at,\n        coalesce(schema_changes.number_of_schema_changes_last_month, 0) as number_of_schema_changes_last_month,\n        count(case when connector_recent_logs.event_type = 'SEVERE' then connector_recent_logs.message_data else null end) as number_errors_since_last_completed_sync,\n        count(case when connector_recent_logs.event_type = 'WARNING' then connector_recent_logs.message_data else null end) as number_warnings_since_last_completed_sync\n\n    from connector_recent_logs\n    left join schema_changes \n        on connector_recent_logs.connector_id = schema_changes.connector_id \n\n    join destination on destination.destination_id = connector_recent_logs.destination_id\n\n    -- need explicit group bys for SQL Server\n    group by \n        connector_recent_logs.connector_id, \n        connector_recent_logs.connector_name, \n        connector_recent_logs.connector_type, \n        connector_recent_logs.destination_id, \n        destination.destination_name, \n        connector_recent_logs.connector_health, \n        connector_recent_logs.last_successful_sync_completed_at, \n        connector_recent_logs.last_sync_started_at, \n        connector_recent_logs.last_sync_completed_at, \n        connector_recent_logs.set_up_at, \n        schema_changes.number_of_schema_changes_last_month\n)\n\nselect * \nfrom final", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__connector_status\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.337886Z", "completed_at": "2024-03-15T20:12:03.362629Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.365695Z", "completed_at": "2024-03-15T20:12:03.365701Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.035778045654296875, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_stg_fivetran_platform__connector_connector_name__destination_id.38a4da659a", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        connector_name, destination_id\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__connector\"\n    group by connector_name, destination_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.369202Z", "completed_at": "2024-03-15T20:12:03.384896Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.388796Z", "completed_at": "2024-03-15T20:12:03.388803Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02330923080444336, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_stg_fivetran_platform__log_log_id__created_at.c406abd91d", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        log_id, created_at\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\"\n    group by log_id, created_at\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.374824Z", "completed_at": "2024-03-15T20:12:03.389671Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.392012Z", "completed_at": "2024-03-15T20:12:03.392016Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.020496129989624023, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.fivetran_platform__usage_mar_destination_history", "compiled": true, "compiled_code": "with table_mar as (\n    \n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__mar_table_history\"\n),\n\ncredits_used as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__credits_used\"\n),\n\nuseage_cost as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__usage_cost\"\n),\n\ndestination_mar as (\n\n    select \n        cast(measured_month as date) as measured_month,\n        destination_id,\n        destination_name,\n        sum(free_monthly_active_rows) as free_monthly_active_rows,\n        sum(paid_monthly_active_rows) as paid_monthly_active_rows,\n        sum(total_monthly_active_rows) as total_monthly_active_rows\n    from table_mar\n    group by measured_month, destination_id, destination_name\n),\n\nusage as (\n\n    select \n        coalesce(credits_used.destination_id, useage_cost.destination_id) as destination_id,\n        credits_used.credits_spent,\n        useage_cost.dollars_spent,\n        cast(concat(coalesce(credits_used.measured_month,useage_cost.measured_month), '-01') as date) as measured_month -- match date format to join with MAR table\n    from credits_used\n    full outer join useage_cost\n        on useage_cost.measured_month = credits_used.measured_month\n        and useage_cost.destination_id = credits_used.destination_id\n),\n\njoin_usage_mar as (\n\n    select \n        destination_mar.measured_month,\n        destination_mar.destination_id,\n        destination_mar.destination_name,\n        usage.credits_spent,\n        usage.dollars_spent,\n        destination_mar.free_monthly_active_rows,\n        destination_mar.paid_monthly_active_rows,\n        destination_mar.total_monthly_active_rows,\n\n        -- credit and usage mar calculations\n        round( cast(nullif(usage.credits_spent,0) * 1000000.0 as numeric(28,6)) / cast(nullif(destination_mar.total_monthly_active_rows,0) as numeric(28,6)), 2) as credits_spent_per_million_mar,\n        round( cast(nullif(destination_mar.total_monthly_active_rows,0) * 1.0 as numeric(28,6)) / cast(nullif(usage.credits_spent,0) as numeric(28,6)), 0) as mar_per_credit_spent,\n        round( cast(nullif(usage.dollars_spent,0) * 1000000.0 as numeric(28,6)) / cast(nullif(destination_mar.total_monthly_active_rows,0) as numeric(28,6)), 2) as amount_spent_per_million_mar,\n        round( cast(nullif(destination_mar.total_monthly_active_rows,0) * 1.0 as numeric(28,6)) / cast(nullif(usage.dollars_spent,0) as numeric(28,6)), 0) as mar_per_amount_spent\n    from destination_mar \n    left join usage \n        on destination_mar.measured_month = cast(usage.measured_month as date)\n        and destination_mar.destination_id = usage.destination_id\n)\n\nselect * \nfrom join_usage_mar", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__usage_mar_destination_history\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.381177Z", "completed_at": "2024-03-15T20:12:03.389956Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.392295Z", "completed_at": "2024-03-15T20:12:03.392299Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.020611047744750977, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_fivetran_platform__mar_table_history_connector_id__destination_id__schema_name__table_name__measured_month.b7babb1441", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        connector_id, destination_id, schema_name, table_name, measured_month\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__mar_table_history\"\n    group by connector_id, destination_id, schema_name, table_name, measured_month\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.385234Z", "completed_at": "2024-03-15T20:12:03.390550Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.392806Z", "completed_at": "2024-03-15T20:12:03.392810Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.026530742645263672, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_fivetran_platform__audit_user_activity_log_id__occurred_at.be572689a3", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        log_id, occurred_at\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__audit_user_activity\"\n    group by log_id, occurred_at\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.394095Z", "completed_at": "2024-03-15T20:12:03.416364Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.432935Z", "completed_at": "2024-03-15T20:12:03.432943Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.04246711730957031, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.fivetran_platform__audit_table", "compiled": true, "compiled_code": "\n\nwith sync_log as (\n    \n    select \n        *,\n        \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{table}'\n    else null end\n\n as table_name\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\"\n    where event_subtype in ('sync_start', 'sync_end', 'write_to_table_start', 'write_to_table_end', 'records_modified')\n\n    \n\n    and cast(created_at as date) > \n\n\n\n    coalesce(\n        (select \n\n    max(sync_start_day) + ((interval '1 day') * (-7))\n\n \n            from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__audit_table\"), \n        '2010-01-01'\n        )\n\n\n\n    \n),\n\nconnector as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__connector_status\"\n),\n\nadd_connector_info as (\n\n    select \n        sync_log.*,\n        connector.connector_name,\n        connector.destination_id,\n        connector.destination_name\n    from sync_log \n    left join connector\n        on connector.connector_id = sync_log.connector_id\n),\n\nsync_timestamps as (\n\n    select\n        connector_id,\n        connector_name,\n        table_name,\n        event_subtype,\n        destination_id,\n        destination_name,\n        created_at as write_to_table_start,\n        min(case when event_subtype = 'write_to_table_end' then created_at else null end) \n            over (partition by connector_id, table_name order by created_at ROWS between CURRENT ROW AND UNBOUNDED FOLLOWING) as write_to_table_end,\n\n        max(case when event_subtype = 'sync_start' then created_at else null end) \n            over (partition by connector_id order by created_at ROWS between UNBOUNDED PRECEDING and CURRENT ROW) as sync_start,\n\n        min(case when event_subtype = 'sync_end' then created_at else null end) \n            over (partition by connector_id order by created_at ROWS between CURRENT ROW AND UNBOUNDED FOLLOWING) as sync_end, -- coalesce with next_sync_start\n\n        min(case when event_subtype = 'sync_start' then created_at else null end) \n            over (partition by connector_id order by created_at ROWS between CURRENT ROW AND UNBOUNDED FOLLOWING) as next_sync_start\n    from add_connector_info\n),\n\n-- this will be the base for every record in the final CTE\nlimit_to_table_starts as (\n\n    select *\n    from sync_timestamps \n    where event_subtype = 'write_to_table_start'\n),\n\nrecords_modified_log as (\n\n    select \n        connector_id,\n        created_at,\n        \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{table}'\n    else null end\n\n as table_name,\n        \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{schema}'\n    else null end\n\n as schema_name,\n        \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{operationType}'\n    else null end\n\n as operation_type,\n        cast (\n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{count}'\n    else null end\n\n as bigint) as row_count\n    from sync_log \n    where event_subtype = 'records_modified'\n\n),\n\nsum_records_modified as (\n\n    select\n        limit_to_table_starts.connector_id,\n        limit_to_table_starts.connector_name,\n        coalesce(records_modified_log.schema_name, limit_to_table_starts.connector_name) as schema_name,\n        limit_to_table_starts.table_name,\n        limit_to_table_starts.destination_id,\n        limit_to_table_starts.destination_name,\n        limit_to_table_starts.write_to_table_start,\n        limit_to_table_starts.write_to_table_end,\n        limit_to_table_starts.sync_start,\n        case when limit_to_table_starts.sync_end > limit_to_table_starts.next_sync_start then null else limit_to_table_starts.sync_end end as sync_end,\n        sum(case when records_modified_log.operation_type = 'REPLACED_OR_INSERTED' then records_modified_log.row_count else 0 end) as sum_rows_replaced_or_inserted,\n        sum(case when records_modified_log.operation_type = 'UPDATED' then records_modified_log.row_count else 0 end) as sum_rows_updated,\n        sum(case when records_modified_log.operation_type = 'DELETED' then records_modified_log.row_count else 0 end) as sum_rows_deleted\n    from limit_to_table_starts\n    left join records_modified_log on \n        limit_to_table_starts.connector_id = records_modified_log.connector_id\n        and limit_to_table_starts.table_name = records_modified_log.table_name\n\n        -- confine it to one sync\n        and records_modified_log.created_at > limit_to_table_starts.sync_start \n        and records_modified_log.created_at < coalesce(limit_to_table_starts.sync_end, limit_to_table_starts.next_sync_start) \n\n    -- explicit group by needed for SQL Server\n    group by \n        limit_to_table_starts.connector_id,\n        limit_to_table_starts.connector_name,\n        coalesce(records_modified_log.schema_name, limit_to_table_starts.connector_name),\n        limit_to_table_starts.table_name,\n        limit_to_table_starts.destination_id,\n        limit_to_table_starts.destination_name,\n        limit_to_table_starts.write_to_table_start,\n        limit_to_table_starts.write_to_table_end,\n        limit_to_table_starts.sync_start,\n        case when limit_to_table_starts.sync_end > limit_to_table_starts.next_sync_start then null else limit_to_table_starts.sync_end end\n),\n\nfinal as (\n\n    select \n        *,\n        md5(cast(coalesce(cast(schema_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(connector_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(destination_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(table_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(write_to_table_start as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as unique_table_sync_key, -- for incremental materialization \n        cast(date_trunc('day', sync_start) as date) as sync_start_day -- for partitioning\n    from sum_records_modified\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__audit_table\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.429936Z", "completed_at": "2024-03-15T20:12:03.434224Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.436531Z", "completed_at": "2024-03-15T20:12:03.436537Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.022248268127441406, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_fivetran_platform__connector_status_connector_id__destination_id.1d83a6dd89", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        connector_id, destination_id\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__connector_status\"\n    group by connector_id, destination_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.426303Z", "completed_at": "2024-03-15T20:12:03.434483Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.436945Z", "completed_at": "2024-03-15T20:12:03.436950Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02318882942199707, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.fivetran_platform__schema_changelog", "compiled": true, "compiled_code": "with schema_changes as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\"\n\n    where event_subtype in ('create_table', 'alter_table', 'create_schema', 'change_schema_config')\n),\n\nconnector as (\n\n    select *\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__connector_status\"\n),\n\nadd_connector_info as (\n\n    select \n        schema_changes.*,\n        connector.connector_name,\n        connector.destination_id,\n        connector.destination_name\n\n    from schema_changes join connector \n        on schema_changes.connector_id = connector.connector_id\n),\n\nfinal as (\n\n    select\n        connector_id,\n        connector_name,\n        destination_id,\n        destination_name,\n        created_at,\n        event_subtype,\n        message_data,\n\n        case \n        when event_subtype = 'alter_table' then \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{table}'\n    else null end\n\n \n        when event_subtype = 'create_table' then \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{name}'\n    else null end\n\n\n        else null end as table_name,\n\n        case \n        when event_subtype = 'create_schema' or event_subtype = 'create_table' then \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{schema}'\n    else null end\n\n\n        else null end as schema_name\n    \n    from add_connector_info\n)\n\nselect * from final", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__schema_changelog\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.438551Z", "completed_at": "2024-03-15T20:12:03.443473Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.450080Z", "completed_at": "2024-03-15T20:12:03.450087Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.014558076858520508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_fivetran_platform__usage_mar_destination_history_destination_id__measured_month.05f6419efd", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        destination_id, measured_month\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__usage_mar_destination_history\"\n    group by destination_id, measured_month\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.443741Z", "completed_at": "2024-03-15T20:12:03.450948Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.452639Z", "completed_at": "2024-03-15T20:12:03.452643Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.011294126510620117, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.not_null_fivetran_platform__audit_table_unique_table_sync_key.d6c37e48af", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect unique_table_sync_key\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__audit_table\"\nwhere unique_table_sync_key is null\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.447227Z", "completed_at": "2024-03-15T20:12:03.451521Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.453135Z", "completed_at": "2024-03-15T20:12:03.453139Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.014604806900024414, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.unique_fivetran_platform__audit_table_unique_table_sync_key.308ad058f7", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    unique_table_sync_key as unique_field,\n    count(*) as n_records\n\nfrom \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__audit_table\"\nwhere unique_table_sync_key is not null\ngroup by unique_table_sync_key\nhaving count(*) > 1\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.453851Z", "completed_at": "2024-03-15T20:12:03.457894Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.458434Z", "completed_at": "2024-03-15T20:12:03.458438Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.006828784942626953, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_fivetran_platform__schema_changelog_connector_id__destination_id__message_data__created_at.cc39f64493", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        connector_id, destination_id, message_data, created_at\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__schema_changelog\"\n    group by connector_id, destination_id, message_data, created_at\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.416852Z", "completed_at": "2024-03-15T20:12:03.720761Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.721307Z", "completed_at": "2024-03-15T20:12:03.721314Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.33449292182922363, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.fivetran_log.fivetran_platform__connector_daily_events", "compiled": true, "compiled_code": "-- depends_on: \"postgres\".\"fivetran_platform_integration_tests\".\"connector\"\n\nwith connector as (\n    \n    select * \n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__connector_status\"\n),\n\n-- grab api calls, schema changes, and record modifications\nlog_events as (\n\n    select \n        connector_id,\n        cast( date_trunc('day', created_at) as date) as date_day,\n        case \n            when event_subtype in ('create_table', 'alter_table', 'create_schema', 'change_schema_config') then 'schema_change' \n            else event_subtype end as event_subtype,\n\n        sum(case when event_subtype = 'records_modified' then cast( \n\n  case when message_data ~ '^\\s*[\\{].*[\\}]?\\s*$' -- Postgres has no native json check, so this will check the string for indicators of a JSON object\n    then message_data::json #>> '{count}'\n    else null end\n\n as bigint )\n        else 1 end) as count_events \n\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"stg_fivetran_platform__log\"\n\n    where event_subtype in ('api_call', \n                            'records_modified', \n                            'create_table', 'alter_table', 'create_schema', 'change_schema_config') -- all schema changes\n                            \n        and connector_id is not null\n\n    group by connector_id, cast( date_trunc('day', created_at) as date), event_subtype\n),\n\npivot_out_events as (\n\n    select\n        connector_id,\n        date_day,\n        max(case when event_subtype = 'api_call' then count_events else 0 end) as count_api_calls,\n        max(case when event_subtype = 'records_modified' then count_events else 0 end) as count_record_modifications,\n        max(case when event_subtype = 'schema_change' then count_events else 0 end) as count_schema_changes\n\n    from log_events\n    group by connector_id, date_day\n), \n\nconnector_event_counts as (\n\n    select\n        pivot_out_events.date_day,\n        pivot_out_events.count_api_calls,\n        pivot_out_events.count_record_modifications,\n        pivot_out_events.count_schema_changes,\n        connector.connector_name,\n        connector.connector_id,\n        connector.connector_type,\n        connector.destination_name,\n        connector.destination_id,\n        connector.set_up_at\n    from\n    connector left join pivot_out_events \n        on pivot_out_events.connector_id = connector.connector_id\n),\n\nspine as (\n\n    \n    \n    \n    \n    \n\n    select \n        cast(date_day as date) as date_day\n    from (\n        \n\n    \n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 1827\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n    cast('2019-03-22' as date) + ((interval '1 day') * (row_number() over (order by 1) - 1))\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= \n\n    date_trunc('day', \n    current_timestamp::timestamp\n) + ((interval '1 week') * (1))\n\n\n\n)\n\nselect * from filtered\n\n\n        \n \n    ) as date_spine\n),\n\nconnector_event_history as (\n\n    select\n        spine.date_day,\n        connector_event_counts.connector_name,\n        connector_event_counts.connector_id,\n        connector_event_counts.connector_type,\n        connector_event_counts.destination_name,\n        connector_event_counts.destination_id,\n        max(case \n            when spine.date_day = connector_event_counts.date_day then connector_event_counts.count_api_calls\n            else 0\n        end) as count_api_calls,\n        max(case \n            when spine.date_day = connector_event_counts.date_day then connector_event_counts.count_record_modifications\n            else 0\n        end) as count_record_modifications,\n        max(case \n            when spine.date_day = connector_event_counts.date_day then connector_event_counts.count_schema_changes\n            else 0\n        end) as count_schema_changes\n    from\n    spine join connector_event_counts\n        on spine.date_day  >= cast(date_trunc('day', cast(connector_event_counts.set_up_at as date)) as date)\n\n    group by spine.date_day, connector_name, connector_id, connector_type, destination_name, destination_id\n),\n\n-- now rejoin spine to get a complete calendar\njoin_event_history as (\n    \n    select\n        spine.date_day,\n        connector_event_history.connector_name,\n        connector_event_history.connector_id,\n        connector_event_history.connector_type,\n        connector_event_history.destination_name,\n        connector_event_history.destination_id,\n        max(connector_event_history.count_api_calls) as count_api_calls,\n        max(connector_event_history.count_record_modifications) as count_record_modifications,\n        max(connector_event_history.count_schema_changes) as count_schema_changes\n\n    from\n    spine left join connector_event_history\n        on spine.date_day = connector_event_history.date_day\n\n    group by spine.date_day, connector_name, connector_id, connector_type, destination_name, destination_id\n),\n\nfinal as (\n\n    select *\n    from join_event_history\n\n    where date_day <= cast(\n    current_timestamp::timestamp\n as date)\n)\n\nselect *\nfrom final", "relation_name": "\"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__connector_daily_events\""}, {"status": "success", "timing": [{"name": "compile", "started_at": "2024-03-15T20:12:03.750769Z", "completed_at": "2024-03-15T20:12:03.754753Z"}, {"name": "execute", "started_at": "2024-03-15T20:12:03.755270Z", "completed_at": "2024-03-15T20:12:03.755275Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.00566411018371582, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.fivetran_log.dbt_utils_unique_combination_of_columns_fivetran_platform__connector_daily_events_connector_id__destination_id__date_day.a279340e8f", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        connector_id, destination_id, date_day\n    from \"postgres\".\"fivetran_platform_integration_tests_fivetran_platform\".\"fivetran_platform__connector_daily_events\"\n    group by connector_id, destination_id, date_day\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null}], "elapsed_time": 1.8332817554473877, "args": {"invocation_command": "dbt docs generate -t postgres", "target": "postgres", "use_colors": true, "log_format_file": "debug", "use_colors_file": true, "print": true, "introspect": true, "quiet": false, "strict_mode": false, "send_anonymous_usage_stats": true, "log_level": "info", "show_resource_report": false, "which": "generate", "compile": true, "write_json": true, "indirect_selection": "eager", "static": false, "log_path": "/Users/joseph.markiewicz/Documents/dbt_packages/fivetran_log/dbt_fivetran_log/integration_tests/logs", "partial_parse": true, "vars": {}, "macro_debugging": false, "log_format": "default", "cache_selected_only": false, "static_parser": true, "populate_cache": true, "printer_width": 80, "profiles_dir": "/Users/joseph.markiewicz/.dbt", "empty_catalog": false, "defer": false, "log_file_max_bytes": 10485760, "version_check": true, "partial_parse_file_diff": true, "exclude": [], "enable_legacy_logger": false, "select": [], "favor_state": false, "log_level_file": "debug", "project_dir": "/Users/joseph.markiewicz/Documents/dbt_packages/fivetran_log/dbt_fivetran_log/integration_tests", "warn_error_options": {"include": [], "exclude": []}}}